# -*- coding: utf-8 -*-
"""Implementation using CART Algorithms & Ensembling Boosting(Final_deliverable).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T-FkC-6gV7-t1D3jvHhxA-wKIb05oQGD

### Data Pre-processing and Exploratory Data Analysis

<font color="red"> <b> Contributors </b> </font>

<font color="green"> <b>
- Aditya Sapara (21BCE258)  
- Priyanshu Savla (21BCE265)
- Jay Valaki (21BCE312)

</b></font>

## <font color="red"> Data Understanding and EDA </font>

# Dataset : Adult Census Income from Kaggle
### Source of the Data :  
https://www.kaggle.com/uciml/adult-census-income


A brief description of the features are as follows:
Attributes:
income (Target Variable): >50K, <=50K <br/>
Predictors :-<br/>

age: continuous<br/>
workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked<br/>
fnlwgt: continuous<br/>
education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool<br/>
education-num: continuous<br/>
marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse<br/>
occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces <br/>
relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried <br/>
race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black <br/>
sex: Female, Male <br/>
capital-gain: continuous<br/>
capital-loss: continuous<br/>
hours-per-week: continuous<br/>
native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands

## Exploratory Data Analysis (EDA)
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from copy import deepcopy as copy
# %matplotlib inline

"""### Reading the Data"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('adult.csv')

df.head()

"""### View summary of dataframe"""

df.info()

df.head()

df.columns

df.describe()

df.shape

"""### Preprocessing of the data"""

df.isnull().values

# Missing Values:
df.isnull().sum()

#Missing Values are represented as Question Marks in this Dataset.
print("No of Missing Values in each categorical column ")
print(f"workclass : {sum(df['workclass']=='?')}")
print(f"education : {sum(df['education']=='?')}")
print(f"marital.status : {sum(df['marital.status']=='?')}")
print(f"occupation : {sum(df['occupation']=='?')}")
print(f"relationship : {sum(df['relationship']=='?')}")
print(f"race : {sum(df['race']=='?')}")
print(f"sex : {sum(df['sex']=='?')}")
print(f"native.country : {sum(df['native.country']=='?')}")
print(f"income : {sum(df['income']=='?')}")

df

#Removing Missing Values:
df1 = df[(df['workclass']!='?')&(df['occupation']!='?')&(df['native.country']!='?')].copy(deep = True)
df1.head()

df1.isnull().sum()

df1["income"].unique()

df1.shape

df1.info()

df1

# Identify Numeric features
numeric_features = ['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']

# Identify Categorical features
cat_features = ['workclass','education','marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income']

df1.head()

df1

df1["income"].value_counts()

"""### Data Visualization"""

import seaborn as sns

g = sns.pairplot(df)
g.fig.set_size_inches(40,40)

import matplotlib.pyplot as plt
sns.countplot(x="income", data=df)
plt.figure(figsize=(20,10))

"""##### The proportion of records having income less than 50K dollars is more than the proportion of records having more than 50k dollars.#####"""

fig, ax = plt.subplots(nrows=2,ncols=3, figsize=(40,30))
sns.countplot(x="sex", data=df1,hue="income",ax = ax[0][0])
cp = sns.countplot(x="marital.status", data=df1,hue="income",ax = ax[0][1])
cp.set_xticklabels(cp.get_xticklabels(), rotation=40, ha="right")
cp2 = sns.countplot(x="education", data=df1,hue="income",ax = ax[0][2])
cp2.set_xticklabels(cp2.get_xticklabels(), rotation=40, ha="right")
cp3 = sns.countplot(x="race", data=df1,hue="income",ax = ax[1][0])
cp3.set_xticklabels(cp3.get_xticklabels(), rotation=40, ha="right")
cp4 = sns.countplot(x="relationship", data=df1,hue="income", ax = ax[1][1])
cp4.set_xticklabels(cp4.get_xticklabels(), rotation=40, ha="right")
cp5 = sns.countplot(x="occupation", data=df1,hue="income",ax= ax[1][2])
cp5.set_xticklabels(cp5.get_xticklabels(), rotation=40, ha="right")

plt.tight_layout()

viol_plot = sns.catplot(x="race", y="fnlwgt", hue="income",data=df1, kind="violin")
viol_plot.ax.legend(loc=2)
viol_plot.set_xticklabels(rotation=30,ha = "right")
plt.tight_layout()

g = sns.catplot(x="occupation", y="fnlwgt", hue="income", data=df1)
g.set_xticklabels(rotation=30,ha = "right")
plt.tight_layout()

#Box plots

df1.drop(['education.num','income'],axis = 1).plot(kind='box', subplots=True, layout=(2,3), sharex=False, sharey=False,
        figsize=(9,9),title='Box Plot of Income variable')

# Distribution Plots:
sns.distplot(df1['age'],kde = True,bins = 30)

plt.hist(x = df1['age'],histtype='bar',facecolor = 'g')

sns.distplot(df1['education.num'],kde = False)

sns.distplot(df1['hours.per.week'],kde = False)

sns.jointplot(x ="age", y="hours.per.week", data=df1,kind="hex")
#sns.jointplot(x='total_bill',y='tip',data=tips,kind='hex')
#kind must be either 'scatter', 'reg', 'resid', 'kde', or 'hex

"""#### The hours.per week value of most of the people is 40  """

sns.regplot(x='capital.gain', y='capital.loss',data = df1, marker="+")

"""#### The values of capital.gain and capital.loss are zeroes"""

sns.jointplot(x="hours.per.week",y ="fnlwgt",data=df1,kind="scatter")

"""####  The people having hours.per.week in between 25 to 75 have higher fnlwgt values."""

sns.jointplot(x="fnlwgt", y="age", data=df1, kind="kde")

"""#### The fnlwgt values are moslty in the range of 0-40,000 and are of age 20 to 40."""

numeric_df = df1.select_dtypes(include=['int64', 'float64'])
cr = numeric_df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(cr, annot=True, cmap='YlOrBr')
plt.show()

def outL_func(q25,q75):
    return (q75 + 1.5*(q75-q25))

def outR_func(q25,q75):
    return (q25 - 1.5*(q75-q25))

def out_rem(x,outL,outR):
    if x>outR:
        return outR

    elif x<outL:
        return outL
    else :
        return x

import numpy as np

df1.head()

labels = ['age','fnlwgt','hours.per.week']
for label in labels :
    q25,q75 = q75, q25 = np.percentile(df1[label], [75,25])
    outL = outL_func(q25,q75)
    outR = outR_func(q25,q75)
    df1[label]= df1[label].apply(lambda row: out_rem(row,outL,outR))

"""
### Working on categorical variables
"""

from sklearn import preprocessing

le = preprocessing.LabelEncoder()

df1['workclass'] = le.fit_transform(df1['workclass'])
df1['education'] = le.fit_transform(df1['education'])
df1['marital.status'] = le.fit_transform(df1['marital.status'])
df1['occupation'] = le.fit_transform(df1['occupation'])
df1['relationship'] = le.fit_transform(df1['relationship'])
df1['race'] = le.fit_transform(df1['race'])
df1['sex'] = le.fit_transform(df1['sex'])
df1['native.country'] = le.fit_transform(df1['native.country'])

# Transforming the target variable to 0s if income is less than 50k and 1 if income is greater than 50k
#df2_income[df2_income['income']=='<=50K'] = -1
#df2_income[df2_income['income']=='>50K'] = 1

df1["income"]= df1["income"].apply(lambda x: -1 if x == '<=50K' else 1  )

df1

df1['income'].value_counts()

df1.head()

t=df1.income
t=t.values.reshape(-1,1)
t

X=df1[:]
X=X.drop(['income'], axis=1)
X.shape

X.shape

t.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, t, test_size=0.30, random_state=42)

from sklearn.linear_model import LogisticRegression

model1 = LogisticRegression().fit(X_train, y_train)

y_predict=model1.predict(X_test)
#pred_model2=model2.predict(X_test)
print("Logistic Regression Score : ",model1.score(X_test, y_test))

from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score
cf=confusion_matrix(y_test, y_predict)
TP=cf[1][1]
TN=cf[0][0]
FN=cf[1][0]
FP=cf[0][1]
sns.heatmap(confusion_matrix(y_test, y_predict),cmap='Reds', annot=True, fmt='d')
plt.title("Logistic Regression Confusion Matrix")

print('Accuracy on test:', accuracy_score(y_test,y_predict),"\n")
print('F1 score on test:', f1_score(y_test,y_predict),"\n")
precision=(TP/(TP+FP))
print("Precision :" , precision,"\n")
specificity=TN/(TN+FP)
print("Specificity :" , specificity,"\n")
recall=TP/(TP+FN)
print("Recall :" , recall,"\n")

plt.title("Y prediction")
plt.plot(y_predict[0:100])
plt.show()
plt.title("Y test")
plt.plot(y_test[0:100])
plt.show()
plt.title("Y pred vs Y test")
plt.plot(y_predict[0:100])
plt.plot(y_test[0:100])
plt.show()

from sklearn.metrics import roc_auc_score, roc_curve, auc
false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_predict)
roc_auc = auc(false_positive_rate, true_positive_rate)
plt.plot(false_positive_rate, true_positive_rate, 'b',
label='AUC = %0.4f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.1,1.5])
plt.ylim([-0.1,1.5])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
print("ROC AUC Score : ", roc_auc_score(y_test, y_predict))

"""### Preliminary Observations

1. The no of records having income less than 50k dollars is more than the no of records having income more than 50k dollars income. The dataset neeeds to be balanced with the target values so that the models do not overfit the data.
2. The capital.gain and capital.loss values contain zeroes ,so these columns can be dropped.<br/>
3. Scatter plots and bar plots are plotted to find the distribution of various values of categorical values.
4. Hours.per.week has a value of 40 in most of the records, so this field can be dropped.
5. The fnlwgt values are moslty in the range of 0-40,000 and are of age 20 to 40.
6. The outliers are present in some of the contiuous variables which need to the handled properly.

## Logistic regression with PCA
"""

from sklearn.decomposition import PCA
pca = PCA()
X_train = pca.fit_transform(X_train)
pca.explained_variance_ratio_

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import GradientBoostingClassifier

"""## Prediction using CART(classification and Regression Trees)

### Establishing Random Forest Search Classification Model
"""

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=100, random_state=24)
rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)

print("Random Forests accuracy", accuracy_score(y_test, y_pred))

"""### Pruning the model to improve the performance"""

rfc = RandomForestClassifier(n_estimators=100,criterion="gini", max_depth=3)
model_rfc = rfc.fit(X_train,y_train)
pred_rf = rfc.predict(X_test)
Random_Forests_accuracy = accuracy_score(y_test, pred_rf)

print("Random Forests accuracy", accuracy_score(y_test, pred_rf))

"""We observe an increase in the accracy score of the model after we had pruned the Random Forest

from sklearn.tree import DecisionTreeClassifier
dct = DecisionTreeClassifier()
model_dct = rf.fit(X_train,y_train)
pred_dct = rf.predict(X_test)
Decision_Tree_accuracy = accuracy_score(y_test, pred_dct)
"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier(criterion='gini',random_state=24, max_depth=5)

dtree.fit(X_train, y_train)
tree_pred = dtree.predict(X_test)

print("Decision Tree accuracy: ", accuracy_score(y_test, tree_pred))

"""Both the Random Forest and Decision Tree return similar prediction accuracy scores. However, Random Forest is marginally better and thus, it is the selected model.

We will now optimize the Random Forest Classifier by tuning the Hyperparameters.

### Hyperparameter Tuning (Fine Tuning of parameters)

The random forest hyperparameters we will tune are the following:

- n_estimators: represents the number of trees in the forest. More trees translates to better learning from the data, however at the cost of performance. Thus, a careful consideration must be placed on what is the optimal value.

- max_features: the number of features to consider before making a split. A high value causes overfitting. Thus, an optimized value must be found.

- min_samples_leaf: the minimum number of samples needed for a node to be considered a leaf node. Increasing this value can cause underfitting.

## Methodology
First we do a Randomized Search to narrow down the possibilites and then perform a Grid Search to further optimize the model. This approach is more suited since directly running a Grid Search is computationally intensive.

### Randomized Search
"""

#Randomized Search

from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, KFold

n_estimators = np.arange(100, 1000, 100)
max_features = np.arange(1, 10, 1)
min_samples_leaf = np.arange(2, 10, 1)
kfold = KFold(n_splits = 3)
start_grid = {
    'n_estimators': n_estimators,
    'max_features': max_features,
    'min_samples_leaf': min_samples_leaf,
    }

rf = RandomForestClassifier()

test_rf = RandomizedSearchCV(estimator=rf, param_distributions=start_grid, cv=kfold)
print(start_grid)

from sklearn import metrics

test_rf.fit(X_train, y_train)
test_rf.best_params_

test_rf.predict(X_test)
metrics.accuracy_score(y_test, y_pred)

print(test_rf.best_score_)

"""### Grid Search"""

kfold_gs = KFold(n_splits=3)
n_estimators = np.arange(100, 500, 50)
max_features = np.arange(1, 5, 1)
min_samples_leaf = np.arange(2, 5, 1)

gs_grid = {
    'n_estimators': n_estimators,
    'max_features': max_features,
    'min_samples_leaf': min_samples_leaf
}

test_grid = GridSearchCV(estimator = rf, param_grid=gs_grid, cv=kfold_gs)
res = test_grid.fit(X_train, y_train)

print(res.best_params_)
print(res.best_score_)

res.predict(X_test)
metrics.accuracy_score(y_test, y_pred)

"""<b>Hence as observed, the accuarcy score of Random search CV has proven to be a better CART algorithm when compared to a Grid Seacrh CV when dealing with large dataset.Model tuning is the process of finding the best machine learning model hyperparameters for a particular data set. Random and Grid Search are two uniformed methods for hyperparameter tuning<b>

### Building the final Model after Hyper parameter tuning the model
"""

final_model = RandomForestClassifier(n_estimators=450, min_samples_leaf=3, max_features=3, random_state=24)
final_model.fit(X_train, y_train)

pip install shap

import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import shap

# Create a synthetic dataset (replace with your actual dataset)
# X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)

# Split the dataset into training and testing sets
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize and train the final RandomForestClassifier
# final_model = RandomForestClassifier(n_estimators=450, min_samples_leaf=3, max_features=3, random_state=24)
# final_model.fit(X_train, y_train)

# Make predictions on the test set
# y_pred = final_model.predict(X_test)

# Evaluate the classifier
# accuracy = accuracy_score(y_test, y_pred)
# print(f'Accuracy: {accuracy:.2f}')

# Use SHAP to explain the model's predictions
explainer = shap.Explainer(final_model, X_train)
shap_values = explainer(X_test)

# Plot the SHAP values for feature importance
shap.summary_plot(shap_values, X_test, feature_names=[f'Feature {i}' for i in range(X.shape[1])])

shap_values

if len(shap_values.values.shape) > 2:
    average_shap_values_rf = np.mean(shap_values.values, axis=2)
    plt.figure()
    shap.summary_plot(average_shap_values_rf, X_test, feature_names=feature_names, title="Random Forest Average Feature Importance Across Classes")

import numpy as np
import shap
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, StackingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=450, random_state=42)
bagging_clf.fit(X_train, y_train)
y_pred_bagging = bagging_clf.predict(X_test)
accuracy_bagging = accuracy_score(y_test, y_pred_bagging)
print(f'Bagging Accuracy: {accuracy_bagging:.2f}')





predictions = final_model.predict(X_test)
print(accuracy_score(y_test, predictions))









"""<b> The previous Random Forest Classifier without tuning gave an accuracy score of 0.727. The hyperpaametrized tuned model gives an accuracy score of 0.74005

By fine tuning the model, we are able to get an improvement of 0.0256 or 2.56%</b>

### Ensemble Technique Bagging
<b>Increasing the Accuracy by Applying Ensemble technique BAGGING to our final tuned random forest model</b>
"""

from sklearn.ensemble import BaggingClassifier

ensembled_bag = BaggingClassifier(base_estimator=final_model,n_estimators=100)

modeled_ensembled_bag =ensembled_bag.fit(X_train,y_train)
pred_ensembled_bag = ensembled_bag.predict(X_test)

eb=accuracy_score(y_test, pred_ensembled_bag)
print("The Accuracy of BAAGING is ", eb)

import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
plt.figure(figsize=(20,10))
sns.scatterplot(np.arange(0.1, 1, 0.01),f1_score)
plt.xlabel('Threshold')
plt.ylabel('F1 Score')

#Ensemble Technique (Boosting using Adaboost Classifier)

from sklearn.ensemble import AdaBoostClassifier

Adaboost = AdaBoostClassifier(base_estimator=final_model, n_estimators=15)
model_boost =Adaboost.fit(X_train,y_train)
pred_boost = Adaboost.predict(X_test)

Adaboost_cf = accuracy_score(y_test, pred_boost)
print("The Accuracy of BOOSTING is ", Adaboost_cf)

"""**Hence we can observe an improvement in the accuracy score of the fianl model after we use Ensembled Boosting technique **"""

import sklearn.metrics as metrics

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
k_range = np.arange(1, 26)
scores = []
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))
print(max(scores)*100,'%')

# plotting the relationship between K and testing accuracy
plt.plot(k_range, scores)
plt.xlabel('Value of K for KNN')
plt.ylabel('Testing Accuracy')
plt.grid(True)

